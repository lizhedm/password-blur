{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 22, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-832d9336585f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;31m# reformatDataWithTaskNumberAndTasktype(1,'distance')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# reformatDataWithTaskNumberAndTasktype(2,'distance')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0mprocessSecurityAuswertung\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-832d9336585f>\u001b[0m in \u001b[0;36mprocessSecurityAuswertung\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0muser_id_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# get users' answers from csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Security_Auswertung.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdistance_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11138)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:11884)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas/_libs/parsers.c:11755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas/_libs/parsers.c:28765)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 22, saw 3\n"
     ]
    }
   ],
   "source": [
    "# function to calculate levenshtein distance\n",
    "def levenshtein(s, t):\n",
    "        ''' From Wikipedia article; Iterative with two matrix rows. '''\n",
    "        if s == t: return 0\n",
    "        elif len(s) == 0: return len(t)\n",
    "        elif len(t) == 0: return len(s)\n",
    "        v0 = [None] * (len(t) + 1)\n",
    "        v1 = [None] * (len(t) + 1)\n",
    "        for i in range(len(v0)):\n",
    "            v0[i] = i\n",
    "        for i in range(len(s)):\n",
    "            v1[0] = i + 1\n",
    "            for j in range(len(t)):\n",
    "                cost = 0 if s[i] == t[j] else 1\n",
    "                v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)\n",
    "            for j in range(len(v0)):\n",
    "                v0[j] = v1[j]\n",
    "                \n",
    "        return v1[len(t)]\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def processSecurityAuswertung():\n",
    "    \n",
    "    user_id_list = [i for i in range(2,27)]\n",
    "    # get users' answers from csv file\n",
    "    df = pd.read_csv('Security_Auswertung.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "    distance_dic = {}\n",
    "    for user_id in user_id_list:\n",
    "        distance_dic[user_id] = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "    #     row[1] -> user_id, row[2] -> Group, row[3] -> Wordlist, row[4] -> Answers\n",
    "        for user_id in user_id_list:\n",
    "            if str(row[1]) == str(user_id):\n",
    "                distance = levenshtein(row[3],row[4])\n",
    "                distance_dic[user_id].append(distance)\n",
    "\n",
    "    df2 = pd.DataFrame.from_dict(distance_dic, orient='index')\n",
    "#     change column names\n",
    "#     df2.columns = []\n",
    "    df2.to_csv('security_result',sep=',', encoding='ISO-8859-1')\n",
    "\n",
    "def timeWithTaskNumber(task_number):\n",
    "    # get right answer list\n",
    "    right_answers_file = 'right_answers' + str(task_number) + '.csv'\n",
    "    df = pd.read_csv(right_answers_file, encoding = \"ISO-8859-1\")\n",
    "    right_answer_list = df['right_answer'].tolist()\n",
    "    \n",
    "    user_id_list = [i for i in range(2,27)]\n",
    "    # get users' answers from csv file\n",
    "    df = pd.read_csv('results-survey.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "    user_time_dic = {}\n",
    "    for user_id in user_id_list:\n",
    "        user_time_dic[user_id] = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "    #     row[0] -> user_id, row[2] -> time\n",
    "        for user_id in user_id_list:\n",
    "            if str(row[0]) == str(user_id) and str(task_number) in row[1]:\n",
    "                user_time_dic[user_id].append(row[2])\n",
    "\n",
    "    df2 = pd.DataFrame.from_dict(user_time_dic, orient='index')\n",
    "#     change column names\n",
    "    df2.columns = right_answer_list\n",
    "    time_result = 'time_result_' + str(task_number) + '.csv'\n",
    "    df2.to_csv(time_result,sep=',', encoding='ISO-8859-1')\n",
    "    \n",
    "\n",
    "def levenshteinWithTaskNumber(task_number):\n",
    "    # get right answer list\n",
    "    right_answers_file = 'right_answers' + str(task_number) + '.csv'\n",
    "    df = pd.read_csv(right_answers_file, encoding = \"ISO-8859-1\")\n",
    "    right_answer_list = df['right_answer'].tolist()\n",
    "    \n",
    "    user_id_list = [i for i in range(2,27)]\n",
    "    # get users' answers from csv file\n",
    "    df = pd.read_csv('results-survey.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "    user_answer_dic = {}\n",
    "    for user_id in user_id_list:\n",
    "        user_answer_dic[user_id] = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "    #     row[0] -> user_id, row[1] -> input_ifeld, row[3] -> input_text)\n",
    "        for user_id in user_id_list:\n",
    "            if str(row[0]) == str(user_id) and str(task_number) in row[1]:\n",
    "                user_answer_dic[user_id].append(row[3])\n",
    "#     print(user_answer_dic)\n",
    "\n",
    "#     for user_id in user_id_list:\n",
    "#         print(len(user_answer_dic[user_id]))\n",
    "        \n",
    "    user_answer_levenshtein_dic = {}\n",
    "    for user_id in user_id_list:\n",
    "        user_answer_levenshtein_dic[user_id] = []\n",
    "\n",
    "    for user_id in user_answer_dic.keys():\n",
    "        for answer,right_answer in zip(user_answer_dic[user_id],right_answer_list):\n",
    "            distance = levenshtein(answer,right_answer)\n",
    "#             print(user_id,answer,right_answer,distance)\n",
    "            user_answer_levenshtein_dic[user_id].append(distance)\n",
    "    df2 = pd.DataFrame.from_dict(user_answer_levenshtein_dic, orient='index')\n",
    "#     change column names\n",
    "    df2.columns = right_answer_list\n",
    "    levenshtein_result = 'levenshtein_result_' + str(task_number) + '.csv'\n",
    "    df2.to_csv(levenshtein_result,sep=',', encoding='ISO-8859-1')\n",
    "    \n",
    "def createFilterAndDistanceWithTaskNumber(task_number):\n",
    "    # get right answer list\n",
    "    right_answers_file = 'right_answers' + str(task_number) + '.csv'\n",
    "    df = pd.read_csv(right_answers_file, encoding = \"ISO-8859-1\")\n",
    "    right_answer_list = df['right_answer'].tolist()\n",
    "    \n",
    "    filter_and_word_file = 'filter_and_word_' + str(task_number) + '.csv'\n",
    "    df = pd.read_csv(filter_and_word_file, encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    user_id_list = [i for i in range(2,27)]\n",
    "    filter_and_distance_dic = {}\n",
    "    for user_id in user_id_list:\n",
    "        filter_and_distance_dic[user_id] = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for right_answer in right_answer_list:\n",
    "            temp_list = row[right_answer].split('%')\n",
    "            user_answer = temp_list[1]\n",
    "            filter_type = temp_list[0]\n",
    "            distance = levenshtein(user_answer,right_answer)\n",
    "            filter_and_distance = filter_type + '%' + str(distance)\n",
    "            filter_and_distance_dic[index + 2].append(filter_and_distance)\n",
    "    \n",
    "    df2 = pd.DataFrame.from_dict(filter_and_distance_dic, orient='index')\n",
    "    df2.columns = right_answer_list\n",
    "    filter_and_distance = 'filter_and_distance_' + str(task_number) + '.csv'\n",
    "    df2.to_csv(filter_and_distance,sep=',', encoding='ISO-8859-1')\n",
    "    \n",
    "def reformatDataWithTaskNumberAndTasktype(task_number,task_type):\n",
    "    # get right answer list\n",
    "    right_answers_file = 'right_answers' + str(task_number) + '.csv'\n",
    "    df = pd.read_csv(right_answers_file, encoding = \"ISO-8859-1\")\n",
    "    right_answer_list = df['right_answer'].tolist()\n",
    "    \n",
    "    user_id_list = [i for i in range(2,27)]\n",
    "    task_type_dic = {}\n",
    "    for user_id in user_id_list:\n",
    "        task_type_dic[user_id] = []\n",
    "        \n",
    "    filter_list = ['colorhalftone','crystallize','blur','pixelation','plaintext','asterisk']\n",
    "    new_column_names = []\n",
    "    for the_filter in filter_list:\n",
    "        new_column_names.append(the_filter + '_wordtype1_word1')\n",
    "        new_column_names.append(the_filter + '_wordtype1_word2')\n",
    "        new_column_names.append(the_filter + '_wordtype2_word1')\n",
    "        new_column_names.append(the_filter + '_wordtype2_word2')\n",
    "        new_column_names.append(the_filter + '_wordtype3_word1')\n",
    "        new_column_names.append(the_filter + '_wordtype3_word2')\n",
    "    \n",
    "    in_file = 'filter_and_' + task_type + '_' +  str(task_number) + '.csv'\n",
    "    df = pd.read_csv(in_file, encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    for the_filter in filter_list:\n",
    "        for index, row in df.iterrows():\n",
    "            for right_answer in right_answer_list:\n",
    "                temp = row[right_answer]\n",
    "                if the_filter in temp:\n",
    "                    task_type_temp = temp.split('%')[1]\n",
    "                    task_type_dic[index + 2].append(task_type_temp)\n",
    "    \n",
    "    df2 = pd.DataFrame.from_dict(task_type_dic, orient='index')\n",
    "    df2.columns = new_column_names\n",
    "    out_file = task_type + '_' + str(task_number) + '.csv'\n",
    "    df2.to_csv(out_file,sep=',', encoding='ISO-8859-1')\n",
    "    \n",
    "# levenshteinWithTaskNumber(1)\n",
    "# levenshteinWithTaskNumber(2)\n",
    "# timeWithTaskNumber(1)\n",
    "# timeWithTaskNumber(2)\n",
    "# createFilterAndDistanceWithTaskNumber(1)\n",
    "# createFilterAndDistanceWithTaskNumber(2)\n",
    "# reformatDataWithTaskNumberAndTasktype(1,'time')\n",
    "# reformatDataWithTaskNumberAndTasktype(2,'time')\n",
    "# reformatDataWithTaskNumberAndTasktype(1,'distance')\n",
    "# reformatDataWithTaskNumberAndTasktype(2,'distance')\n",
    "processSecurityAuswertung()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
